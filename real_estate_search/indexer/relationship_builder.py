"""
Build property_relationships index from existing Elasticsearch indices.
Creates denormalized documents by reading from properties, neighborhoods, and wikipedia.

This module implements the denormalization strategy for real estate search, combining
data from three separate indices into a single, query-optimized index:

1. Properties index: Core property data (price, bedrooms, location, etc.)
2. Neighborhoods index: Demographic and amenity data for neighborhoods
3. Wikipedia index: Contextual articles about locations and landmarks

The denormalized approach trades storage space for query performance:
- BEFORE: 5-6 separate queries taking ~250ms total
- AFTER: Single query taking ~2-3ms (100x+ faster)

This is a common pattern in search applications where read performance is critical.
"""

import logging
from typing import Dict, List, Any, Optional, Iterator
from pydantic import BaseModel, Field, ConfigDict
from elasticsearch import Elasticsearch, helpers

logger = logging.getLogger(__name__)


class WikipediaArticle(BaseModel):
    """Embedded Wikipedia article structure."""
    
    page_id: str = Field(description="Wikipedia page ID")
    title: str = Field(description="Article title")
    url: Optional[str] = Field(default=None, description="Article URL")
    summary: Optional[str] = Field(default=None, description="Article summary")
    city: Optional[str] = Field(default=None, description="City")
    state: Optional[str] = Field(default=None, description="State")
    relationship_type: str = Field(default="neighborhood_related", description="Type of relationship")
    confidence: float = Field(default=0.8, description="Confidence score")
    relevance_score: Optional[float] = Field(default=None, description="Relevance score")


class NeighborhoodData(BaseModel):
    """Embedded neighborhood data structure."""
    
    neighborhood_id: str = Field(description="Unique neighborhood identifier")
    name: str = Field(description="Neighborhood name")
    city: Optional[str] = Field(default=None, description="City name")
    state: Optional[str] = Field(default=None, description="State name")
    population: Optional[int] = Field(default=None, description="Population count")
    walkability_score: Optional[int] = Field(default=None, description="Walkability score")
    school_rating: Optional[float] = Field(default=None, description="School rating")
    description: Optional[str] = Field(default=None, description="Neighborhood description")
    amenities: List[str] = Field(default_factory=list, description="Available amenities")
    demographics: Optional[Dict[str, Any]] = Field(default=None, description="Demographic data")


class RelationshipDocument(BaseModel):
    """Denormalized property relationship document structure."""
    
    model_config = ConfigDict(extra="forbid")
    
    # Property core fields
    listing_id: str = Field(description="Unique property listing ID")
    property_type: Optional[str] = Field(default=None, description="Type of property")
    price: Optional[float] = Field(default=None, description="Property price")
    bedrooms: Optional[int] = Field(default=None, description="Number of bedrooms")
    bathrooms: Optional[float] = Field(default=None, description="Number of bathrooms")
    square_feet: Optional[int] = Field(default=None, description="Square footage")
    year_built: Optional[int] = Field(default=None, description="Year built")
    lot_size: Optional[int] = Field(default=None, description="Lot size")
    
    # Property details
    address: Optional[Dict[str, Any]] = Field(default=None, description="Property address")
    description: Optional[str] = Field(default=None, description="Property description")
    features: List[str] = Field(default_factory=list, description="Property features")
    amenities: List[str] = Field(default_factory=list, description="Property amenities")
    status: Optional[str] = Field(default=None, description="Listing status")
    listing_date: Optional[str] = Field(default=None, description="Listing date")
    days_on_market: Optional[int] = Field(default=None, description="Days on market")
    price_per_sqft: Optional[float] = Field(default=None, description="Price per square foot")
    
    # Additional property fields
    hoa_fee: Optional[float] = Field(default=None, description="HOA fee")
    parking: Optional[Dict[str, Any]] = Field(default=None, description="Parking information")
    virtual_tour_url: Optional[str] = Field(default=None, description="Virtual tour URL")
    images: List[str] = Field(default_factory=list, description="Property image URLs")
    mls_number: Optional[str] = Field(default=None, description="MLS number")
    tax_assessed_value: Optional[int] = Field(default=None, description="Tax assessed value")
    annual_tax: Optional[float] = Field(default=None, description="Annual tax amount")
    
    # Embedded relationships
    neighborhood: Optional[NeighborhoodData] = Field(default=None, description="Embedded neighborhood data")
    wikipedia_articles: List[WikipediaArticle] = Field(default_factory=list, description="Related Wikipedia articles")
    
    # Search optimization
    combined_text: Optional[str] = Field(default=None, description="Combined searchable text")
    
    # Metadata
    relationship_updated: Optional[str] = Field(default=None, description="Last relationship update")
    data_version: str = Field(default="1.0.0", description="Data version")


class RelationshipBuilderConfig(BaseModel):
    """Configuration for relationship builder."""
    
    batch_size: int = Field(default=100, description="Batch size for processing")
    max_wikipedia_articles: int = Field(default=5, description="Maximum Wikipedia articles per property")
    enable_combined_text: bool = Field(default=True, description="Generate combined search text")


class PropertyRelationshipBuilder:
    """Builds denormalized property relationship documents from Elasticsearch indices."""
    
    def __init__(self, es_client: Elasticsearch, config: Optional[RelationshipBuilderConfig] = None):
        """
        Initialize the relationship builder.
        
        Args:
            es_client: Elasticsearch client instance
            config: Optional configuration settings
        """
        self.es = es_client
        self.config = config or RelationshipBuilderConfig()
        self.logger = logging.getLogger(__name__)
    
    def build_all_relationships(self) -> int:
        """
        Build relationships for all properties in the index.
        
        This is the main entry point that orchestrates the denormalization process:
        1. Validates that source indices exist and have data
        2. Reads properties in batches (default: 100 at a time)
        3. For each property, fetches related neighborhood and Wikipedia data
        4. Combines all data into a single denormalized document
        5. Bulk indexes the combined documents to property_relationships index
        
        Returns:
            Number of relationship documents created
        """
        self.logger.info("Starting property relationships build process")
        
        # Validate prerequisites - ensure properties, neighborhoods, wikipedia indices exist
        if not self._validate_prerequisites():
            return 0
        
        total_created = 0
        processed_count = 0
        
        try:
            # Process properties in batches to avoid memory issues
            # Uses Elasticsearch scroll API via helpers.scan for efficient iteration
            for property_batch in self._get_property_batches():
                if not property_batch:
                    continue
                
                # Build relationships for batch - this is where the magic happens
                # Each property gets enriched with neighborhood and Wikipedia data
                relationships = self._build_batch_relationships(property_batch)
                
                # Index to Elasticsearch using bulk API for efficiency
                # Much faster than indexing documents one at a time
                if relationships:
                    success_count = self._bulk_index_relationships(relationships)
                    total_created += success_count
                    processed_count += len(property_batch)
                    
                    self.logger.info(
                        f"Processed batch: {len(property_batch)} properties, "
                        f"indexed {success_count} relationships. "
                        f"Total: {processed_count} processed, {total_created} indexed"
                    )
            
            self.logger.info(f"âœ… Relationship build complete: {total_created} documents created")
            return total_created
            
        except Exception as e:
            self.logger.error(f"Failed to build relationships: {e}")
            raise
    
    def _validate_prerequisites(self) -> bool:
        """Validate that required indices exist and have data."""
        required_indices = ["properties", "neighborhoods", "wikipedia"]
        
        for index in required_indices:
            if not self.es.indices.exists(index=index):
                self.logger.error(f"Required index '{index}' does not exist")
                return False
            
            count = self.es.count(index=index)["count"]
            if count == 0:
                self.logger.warning(f"Index '{index}' is empty")
            else:
                self.logger.info(f"Index '{index}': {count} documents")
        
        return True
    
    def _get_property_batches(self) -> Iterator[List[Dict[str, Any]]]:
        """Get properties in batches for processing."""
        query = {"query": {"match_all": {}}}
        
        batch = []
        for hit in helpers.scan(
            self.es,
            index="properties",
            query=query,
            size=self.config.batch_size
        ):
            batch.append(hit["_source"])
            
            if len(batch) >= self.config.batch_size:
                yield batch
                batch = []
        
        # Yield remaining items
        if batch:
            yield batch
    
    def _build_batch_relationships(self, properties: List[Dict[str, Any]]) -> List[RelationshipDocument]:
        """
        Build relationship documents for a batch of properties using batch fetching.
        
        Optimized to make only 2 additional queries regardless of batch size:
        1. One query to fetch all neighborhoods
        2. One query to fetch all Wikipedia articles
        """
        # Step 1: Collect all IDs we need to fetch
        neighborhood_ids = set()
        wikipedia_page_ids = set()
        
        for prop in properties:
            if neighborhood_id := prop.get("neighborhood_id"):
                neighborhood_ids.add(neighborhood_id)
        
        # Step 2: Batch fetch all neighborhoods at once
        neighborhoods_map = self._batch_fetch_neighborhoods(list(neighborhood_ids))
        
        # Step 3: Collect Wikipedia IDs from neighborhood correlations
        for neighborhood_data in neighborhoods_map.values():
            if correlations := neighborhood_data.get("wikipedia_correlations"):
                # Primary article
                if primary := correlations.get("primary_wiki_article"):
                    if page_id := primary.get("page_id"):
                        wikipedia_page_ids.add(str(page_id))
                
                # Related articles
                if related := correlations.get("related_wiki_articles"):
                    for article_ref in related[:self.config.max_wikipedia_articles]:
                        if page_id := article_ref.get("page_id"):
                            wikipedia_page_ids.add(str(page_id))
        
        # Step 4: Batch fetch all Wikipedia articles at once
        wikipedia_map = self._batch_fetch_wikipedia_articles(list(wikipedia_page_ids))
        
        # Step 5: Build relationships using pre-fetched data
        relationships = []
        for prop_data in properties:
            try:
                relationship = self._build_single_relationship_optimized(
                    prop_data, 
                    neighborhoods_map, 
                    wikipedia_map
                )
                if relationship:
                    relationships.append(relationship)
            except Exception as e:
                listing_id = prop_data.get("listing_id", "unknown")
                self.logger.error(f"Failed to build relationship for property {listing_id}: {e}")
                continue
        
        return relationships
    
    
    def _batch_fetch_neighborhoods(self, neighborhood_ids: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        Batch fetch neighborhoods using a single terms query.
        
        Returns:
            Dictionary mapping neighborhood_id to neighborhood data
        """
        if not neighborhood_ids:
            return {}
        
        neighborhoods_map = {}
        
        try:
            # Use terms query to fetch all neighborhoods in one request
            query = {
                "query": {
                    "terms": {
                        "neighborhood_id": neighborhood_ids
                    }
                },
                "size": len(neighborhood_ids)  # Ensure we get all requested neighborhoods
            }
            
            response = self.es.search(index="neighborhoods", body=query)
            
            for hit in response["hits"]["hits"]:
                neighborhood_data = hit["_source"]
                neighborhood_id = neighborhood_data.get("neighborhood_id")
                if neighborhood_id:
                    neighborhoods_map[neighborhood_id] = neighborhood_data
            
            self.logger.info(f"Fetched {len(neighborhoods_map)} neighborhoods with 1 query")
            
        except Exception as e:
            self.logger.error(f"Failed to batch fetch neighborhoods: {e}")
        
        return neighborhoods_map
    
    def _batch_fetch_wikipedia_articles(self, page_ids: List[str]) -> Dict[str, Dict[str, Any]]:
        """
        Batch fetch Wikipedia articles using a single terms query.
        
        Returns:
            Dictionary mapping page_id to article data
        """
        if not page_ids:
            return {}
        
        wikipedia_map = {}
        
        try:
            # Use terms query to fetch all articles in one request
            query = {
                "query": {
                    "terms": {
                        "page_id": page_ids
                    }
                },
                "size": len(page_ids)  # Ensure we get all requested articles
            }
            
            response = self.es.search(index="wikipedia", body=query)
            
            for hit in response["hits"]["hits"]:
                article_data = hit["_source"]
                page_id = str(article_data.get("page_id"))
                if page_id:
                    wikipedia_map[page_id] = article_data
            
            self.logger.info(f"Fetched {len(wikipedia_map)} Wikipedia articles with 1 query")
            
        except Exception as e:
            self.logger.error(f"Failed to batch fetch Wikipedia articles: {e}")
        
        return wikipedia_map
    
    def _build_single_relationship_optimized(
        self,
        property_data: Dict[str, Any],
        neighborhoods_map: Dict[str, Dict[str, Any]],
        wikipedia_map: Dict[str, Dict[str, Any]]
    ) -> Optional[RelationshipDocument]:
        """
        Build a single relationship using pre-fetched data.
        
        This replaces the old _build_single_relationship method.
        Uses pre-fetched neighborhoods and Wikipedia articles instead of making individual queries.
        """
        listing_id = property_data.get("listing_id")
        if not listing_id:
            self.logger.warning("Property missing listing_id, skipping")
            return None
        
        # Get neighborhood from pre-fetched map
        neighborhood = None
        neighborhood_data = None
        if neighborhood_id := property_data.get("neighborhood_id"):
            neighborhood_data = neighborhoods_map.get(neighborhood_id)
            if neighborhood_data:
                neighborhood = NeighborhoodData(**neighborhood_data)
        
        # Get Wikipedia articles from pre-fetched map
        wikipedia_articles = []
        if neighborhood_data and "wikipedia_correlations" in neighborhood_data:
            articles_data = self._extract_wikipedia_from_map(
                neighborhood_data["wikipedia_correlations"],
                wikipedia_map
            )
            wikipedia_articles = [WikipediaArticle(**article) for article in articles_data]
        
        # Build combined text if enabled
        combined_text = None
        if self.config.enable_combined_text:
            combined_text = self._build_combined_text(
                property_data, 
                neighborhood_data, 
                [article.model_dump() for article in wikipedia_articles]
            )
        
        # Create relationship document
        relationship_data = {
            **self._extract_property_fields(property_data),
            "neighborhood": neighborhood,
            "wikipedia_articles": wikipedia_articles,
            "combined_text": combined_text,
        }
        
        return RelationshipDocument(**relationship_data)
    
    def _extract_wikipedia_from_map(
        self,
        correlations: Dict[str, Any],
        wikipedia_map: Dict[str, Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Extract Wikipedia articles from pre-fetched map based on correlations.
        """
        articles = []
        
        # Get primary article
        if primary := correlations.get("primary_wiki_article"):
            if page_id := primary.get("page_id"):
                if article_data := wikipedia_map.get(str(page_id)):
                    articles.append({
                        "page_id": str(article_data.get("page_id")),
                        "title": article_data.get("title"),
                        "url": article_data.get("url"),
                        "summary": article_data.get("summary") or article_data.get("short_summary") or article_data.get("long_summary"),
                        "city": article_data.get("city"),
                        "state": article_data.get("state"),
                        "relationship_type": "primary",
                        "confidence": primary.get("confidence", 0.9),
                        "relevance_score": article_data.get("relevance_score")
                    })
        
        # Get related articles
        if related := correlations.get("related_wiki_articles"):
            remaining_slots = self.config.max_wikipedia_articles - len(articles)
            for wiki_ref in related[:remaining_slots]:
                if page_id := wiki_ref.get("page_id"):
                    if article_data := wikipedia_map.get(str(page_id)):
                        articles.append({
                            "page_id": str(article_data.get("page_id")),
                            "title": article_data.get("title"),
                            "url": article_data.get("url"),
                            "summary": article_data.get("summary") or article_data.get("short_summary") or article_data.get("long_summary"),
                            "city": article_data.get("city"),
                            "state": article_data.get("state"),
                            "relationship_type": wiki_ref.get("relationship", "related"),
                            "confidence": wiki_ref.get("confidence", 0.8),
                            "relevance_score": article_data.get("relevance_score")
                        })
        
        return articles
    
    
    def _extract_property_fields(self, property_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract and clean property fields for relationship document."""
        # Define the fields we want to extract
        field_mapping = {
            "listing_id": "listing_id",
            "property_type": "property_type", 
            "price": "price",  # Fixed: field is actually "price" not "listing_price"
            "bedrooms": "bedrooms",
            "bathrooms": "bathrooms",
            "square_feet": "square_feet",
            "year_built": "year_built",
            "lot_size": "lot_size",
            "address": "address",
            "description": "description",
            "features": "features",
            "amenities": "amenities",
            "status": "status",
            "listing_date": "listing_date",
            "days_on_market": "days_on_market",
            "price_per_sqft": "price_per_sqft",
            "hoa_fee": "hoa_fee",
            "parking": "parking",
            "virtual_tour_url": "virtual_tour_url",
            "images": "images",
            "mls_number": "mls_number",
            "tax_assessed_value": "tax_assessed_value",
            "annual_tax": "annual_tax",
        }
        
        extracted = {}
        for dest_field, source_field in field_mapping.items():
            value = property_data.get(source_field)
            if value is not None:
                # Convert timestamp to string for listing_date
                if dest_field == "listing_date" and isinstance(value, (int, float)):
                    value = str(value)
                extracted[dest_field] = value
        
        return extracted
    
    def _build_combined_text(
        self, 
        property_data: Dict[str, Any], 
        neighborhood_data: Optional[Dict[str, Any]], 
        wikipedia_articles: List[Dict[str, Any]]
    ) -> str:
        """Build combined searchable text from all sources."""
        text_parts = []
        
        # Add property description
        if property_data.get("description"):
            text_parts.append(property_data["description"])
        
        # Add neighborhood description
        if neighborhood_data and neighborhood_data.get("description"):
            text_parts.append(neighborhood_data["description"])
        
        # Add Wikipedia summaries
        for article in wikipedia_articles:
            if article.get("summary"):
                text_parts.append(article["summary"])
        
        return " ".join(text_parts)
    
    def _bulk_index_relationships(self, relationships: List[RelationshipDocument]) -> int:
        """
        Bulk index relationships to Elasticsearch.
        
        Uses the Elasticsearch bulk API for efficient indexing:
        - Sends multiple documents in a single HTTP request
        - Much faster than indexing documents individually
        - Automatic retry and error handling via helpers.bulk
        
        The document ID is set to the listing_id to ensure:
        - Updates overwrite existing documents (idempotent)
        - Easy retrieval by property listing ID
        - Consistent with the original properties index
        """
        if not relationships:
            return 0
        
        # Prepare bulk actions - each action specifies index, ID, and document
        actions = []
        for relationship in relationships:
            actions.append({
                "_index": "property_relationships",  # Target index for denormalized data
                "_id": relationship.listing_id,      # Use listing_id as document ID
                "_source": relationship.model_dump(exclude_none=True)  # Pydantic to dict, skip None values
            })
        
        try:
            # Execute bulk indexing with automatic batching and retry logic
            # helpers.bulk handles connection errors, retries, and partial failures
            success_count, failed_items = helpers.bulk(
                self.es, 
                actions,
                chunk_size=self.config.batch_size,  # Process in chunks to avoid memory issues
                request_timeout=60                   # Allow longer timeout for large batches
            )
            
            if failed_items:
                self.logger.warning(f"Some items failed to index: {len(failed_items)} failures")
            
            return success_count
            
        except Exception as e:
            self.logger.error(f"Bulk indexing failed: {e}")
            raise