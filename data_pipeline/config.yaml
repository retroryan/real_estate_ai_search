# Data Pipeline Configuration
# All settings except secrets are configured here
# Use environment variables for: VOYAGE_API_KEY, OPENAI_API_KEY, NEO4J_PASSWORD, ELASTIC_PASSWORD

name: real_estate_data_pipeline
version: 1.0.0

# Spark Configuration
spark:
  app_name: RealEstateDataPipeline
  master: local[*]
  driver_memory: 4g
  executor_memory: 2g

# Data Sources
data_sources:
  properties_files:
    - real_estate_data/properties_sf.json
    - real_estate_data/properties_pc.json
  neighborhoods_files:
    - real_estate_data/neighborhoods_sf.json
    - real_estate_data/neighborhoods_pc.json
  wikipedia_db_path: data/wikipedia/wikipedia.db
  locations_file: real_estate_data/locations.json

# Embedding Configuration
embedding:
  provider: voyage  # voyage, openai, ollama, gemini, mock
  model_name: voyage-3  # Options: voyage-3, voyage-large-2, voyage-code-2
  batch_size: 10  # Smaller batch size for API rate limits
  dimension: 1024  # voyage-3: 1024, voyage-large-2: 1536

# Pipeline Fork Configuration
fork:
  enabled_paths:
    # - graph
    - search  # Uncomment to enable search path

# Output Configuration
output:
  enabled_destinations:
    - parquet
    # - neo4j
    - elasticsearch
  
  parquet:
    base_path: data/processed
    compression: snappy
  
  neo4j:
    uri: bolt://localhost:7687
    database: neo4j
    username: neo4j
    # Password from NEO4J_PASSWORD environment variable
  
  # Uncomment to enable Elasticsearch output
  # elasticsearch:
  #   hosts:
  #     - localhost:9200
  #   index_prefix: real_estate
  #   username: elastic
  #   # Password from ELASTIC_PASSWORD environment variable