# Pipeline Configuration
# This file configures the unified Spark data pipeline

pipeline:
  name: "unified_real_estate_pipeline"
  version: "1.0.0"

spark:
  app_name: "RealEstateDataPipeline"
  master: "local[*]"  # Use "spark://cluster-url:7077" for cluster mode
  memory: "4g"
  executor_memory: "2g"
  config:
    spark.sql.adaptive.enabled: true
    spark.sql.adaptive.coalescePartitions.enabled: true
    spark.serializer: "org.apache.spark.serializer.KryoSerializer"
    spark.sql.shuffle.partitions: 200

data_sources:
  properties_sf:
    path: "real_estate_data/properties_sf.json"
    format: "json"
    enabled: true
    options:
      multiLine: true
  
  properties_pc:
    path: "real_estate_data/properties_pc.json"
    format: "json"
    enabled: true
    options:
      multiLine: true
  
  neighborhoods_sf:
    path: "real_estate_data/neighborhoods_sf.json"
    format: "json"
    enabled: true
    options:
      multiLine: true
  
  neighborhoods_pc:
    path: "real_estate_data/neighborhoods_pc.json"
    format: "json"
    enabled: true
    options:
      multiLine: true
  
  wikipedia:
    path: "data/wikipedia/wikipedia.db"
    format: "sqlite"  # Using pure Python SQLite approach
    enabled: true
    options:
      use_pandas: true  # Use pandas/sqlite3 instead of JDBC

enrichment:
  city_abbreviations:
    SF: "San Francisco"
    PC: "Park City"
    NYC: "New York City"
    LA: "Los Angeles"
  state_abbreviations:
    CA: "California"
    UT: "Utah"
    NY: "New York"
    TX: "Texas"
  normalize_features: true
  add_derived_fields: true
  quality_threshold: 0.7

embedding:
  provider: "voyage"  # ollama | openai | voyage | gemini
  model: "voyage-3"  # voyage-3 | voyage-large-2 | voyage-code-2
  batch_size: 100
  max_retries: 3
  timeout: 30
  # api_url not needed for Voyage - uses default API endpoint
  # VOYAGE_API_KEY should be set in environment or .env file

chunking:
  method: "simple"  # simple | semantic | sentence
  chunk_size: 512
  chunk_overlap: 50

processing:
  enable_quality_checks: true
  min_quality_score: 0.7
  cache_intermediate_results: true
  checkpoint_interval: 1000
  parallel_tasks: 4

output:
  format: "parquet"
  path: "data/processed/unified_dataset"
  partitioning:
    - "entity_type"
    - "state"
  compression: "snappy"
  overwrite: true

logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  console: true
  file: "logs/pipeline.log"